{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador BackPropagattion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import Accuracy\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de las imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **ImageDataGenerator:**\n",
    "   - `train_datagen` y `test_datagen` son instancias de `ImageDataGenerator`. Estas realizan aumentación y normalización de imágenes durante el entrenamiento y la prueba.\n",
    "\n",
    "2. **Flujo de Datos de Entrenamiento y Prueba:**\n",
    "   - `flow_from_directory` crea generadores de flujo de datos desde directorios de imágenes.\n",
    "   - `target_size=(64, 64)` ajusta el tamaño de todas las imágenes a 64x64 píxeles.\n",
    "   - `batch_size=32` define el tamaño del lote para el entrenamiento y la prueba.\n",
    "   - `class_mode='categorical'` indica que se trata de un problema de clasificación multiclase.\n",
    "\n",
    "3. **Directorios de Imágenes:**\n",
    "   - `imagenes` y `imagenes_prueba` son los directorios de donde se obtienen las imágenes para entrenamiento y prueba, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2840 images belonging to 5 classes.\n",
      "Found 387 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    'imagenes',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'imagenes_prueba',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construccion del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Capa Convolucional:**\n",
    "   - `Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3))`: La primera capa convolucional con 32 filtros, cada uno de tamaño 3x3, y activación ReLU. La entrada es de forma (64, 64, 3), indicando imágenes de 64x64 píxeles con 3 canales de color (RGB).\n",
    "\n",
    "2. **Capa de Pooling:**\n",
    "   - `MaxPooling2D(pool_size=(2, 2))`: Capa de reducción de dimensionalidad mediante max pooling con una ventana de 2x2. Esto ayuda a conservar las características más importantes.\n",
    "\n",
    "3. **Aplanamiento:**\n",
    "   - `Flatten()`: Aplana la salida de la capa anterior para prepararla para las capas totalmente conectadas.\n",
    "\n",
    "4. **Capa Densa (Totalmente Conectada):**\n",
    "   - `Dense(units=128, activation='relu')`: Capa densa con 128 unidades y activación ReLU.\n",
    "\n",
    "5. **Capa de Salida:**\n",
    "   - `Dense(units=5, activation='softmax')`: Capa de salida con 5 unidades y activación softmax, adecuada para problemas de clasificación multiclase. Las 5 clases representan autobús, avión, bicicleta, bote y sofá.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=5, activation='softmax'))  # 5 clases: autobus, avion, bicicletas, botes, sofa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilacion del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Optimizador Adam:**\n",
    "   - `Adam(learning_rate=0.0001)`: Se utiliza el optimizador Adam con una tasa de aprendizaje de 0.0001. Adam es un optimizador popular en problemas de aprendizaje profundo.\n",
    "\n",
    "2. **Función de Pérdida Categórica:**\n",
    "   - `loss='categorical_crossentropy'`: La función de pérdida utilizada para entrenar el modelo en problemas de clasificación multiclase.\n",
    "\n",
    "3. **Métricas de Evaluación:**\n",
    "   - `metrics=[Accuracy()]`: Durante el entrenamiento, se mide la precisión del modelo. La métrica de precisión evalúa cuántas predicciones del modelo coinciden con las etiquetas reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=[Accuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "89/89 [==============================] - 20s 222ms/step - loss: 1.3324 - accuracy: 0.0000e+00 - val_loss: 1.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/8\n",
      "89/89 [==============================] - 7s 73ms/step - loss: 1.0800 - accuracy: 0.0000e+00 - val_loss: 1.0933 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/8\n",
      "89/89 [==============================] - 7s 74ms/step - loss: 0.9633 - accuracy: 0.0000e+00 - val_loss: 0.9429 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/8\n",
      "89/89 [==============================] - 7s 74ms/step - loss: 0.8681 - accuracy: 0.0000e+00 - val_loss: 0.9669 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/8\n",
      "89/89 [==============================] - 6s 72ms/step - loss: 0.8103 - accuracy: 0.0000e+00 - val_loss: 0.8119 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/8\n",
      "89/89 [==============================] - 7s 74ms/step - loss: 0.7404 - accuracy: 0.0000e+00 - val_loss: 0.7879 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/8\n",
      "89/89 [==============================] - 7s 73ms/step - loss: 0.6830 - accuracy: 0.0000e+00 - val_loss: 0.7231 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/8\n",
      "89/89 [==============================] - 7s 74ms/step - loss: 0.6381 - accuracy: 0.0000e+00 - val_loss: 0.6930 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_set,\n",
    "    steps_per_epoch=len(train_set),\n",
    "    epochs=8,\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 51ms/step - loss: 0.6930 - accuracy: 0.0000e+00\n",
      "Test loss: 0.692962646484375, Test accuracy: 0.0\n",
      "{'loss': [1.3324187994003296, 1.0799846649169922, 0.9633239507675171, 0.868134081363678, 0.8103399276733398, 0.7403931617736816, 0.6830040812492371, 0.6381073594093323], 'accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [1.1348859071731567, 1.0932586193084717, 0.9428659081459045, 0.9669401049613953, 0.8118992447853088, 0.7878959774971008, 0.7230649590492249, 0.6929625868797302], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "eval_result = model.evaluate(test_set)\n",
    "print(f\"Test loss: {eval_result[0]}, Test accuracy: {eval_result[1]}\")\n",
    "\n",
    "# Si deseas ver el historial de entrenamiento para observar cómo evolucionan las métricas\n",
    "print(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"imagenes_prueba/autobus/2008_004968.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Cargar y Preprocesar la Imagen:**\n",
    "   - `image.load_img(img_path, target_size=(64, 64))`: Carga la imagen desde la ruta especificada y la redimensiona a 64x64 píxeles.\n",
    "   - `image.img_to_array(img)`: Convierte la imagen a un array NumPy.\n",
    "   - `np.expand_dims(img_array, axis=0)`: Expande las dimensiones del array para que coincida con las expectativas del modelo.\n",
    "\n",
    "2. **Normalización:**\n",
    "   - `img_batch /= 255.`: Normaliza los píxeles de la imagen dividiendo por 255, asegurando que estén en el rango [0, 1].\n",
    "\n",
    "3. **Predicción:**\n",
    "   - `model.predict(img_batch)`: Utiliza el modelo preentrenado para hacer una predicción sobre la imagen.\n",
    "   - `np.argmax(prediction)`: Obtiene el índice de la clase predicha con la mayor probabilidad.\n",
    "\n",
    "4. **Traducción de la Etiqueta Numérica:**\n",
    "   - `labels = train_set.class_indices`: Obtiene un diccionario de índices de clases desde el conjunto de entrenamiento.\n",
    "   - `labels = dict((v, k) for k, v in labels.items())`: Invierte el diccionario para mapear índices a etiquetas.\n",
    "   - `labels[prediction_label]`: Obtiene la etiqueta predicha basada en el índice devuelto por la predicción.\n",
    "\n",
    "5. **Impresión del Resultado:**\n",
    "   - `print(f\"El modelo predice que la imagen es un(a) {predicted_label}\")`: Imprime la etiqueta predicha por el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "El modelo predice que la imagen es un(a) autobus\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "\n",
    "# Convertir la imagen a un array y expandir las dimensiones para que se ajuste al modelo\n",
    "img_array = image.img_to_array(img)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "\n",
    " \n",
    "img_batch /= 255.\n",
    "\n",
    "# Hacer la predicción\n",
    "prediction = model.predict(img_batch)\n",
    "prediction_label = np.argmax(prediction)\n",
    "\n",
    "# Traducir la etiqueta numérica a una palabra clave de acuerdo a tu conjunto de datos\n",
    "labels = train_set.class_indices\n",
    "labels = dict((v, k) for k, v in labels.items())\n",
    "predicted_label = labels[prediction_label]\n",
    "\n",
    "print(f\"El modelo predice que la imagen es un(a) {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "\n",
    "# Convertir la imagen a un array y expandir las dimensiones para que se ajuste al modelo\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_index = np.argmax(predictions[0])\n",
    "predicted_label = labels[predicted_index]  # Suponiendo que 'labels' es una lista de las etiquetas de tus clases\n",
    "predicted_probability = predictions[0][predicted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta predicha: autobus, Probabilidad: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Etiqueta predicha: {predicted_label}, Probabilidad: {predicted_probability * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
